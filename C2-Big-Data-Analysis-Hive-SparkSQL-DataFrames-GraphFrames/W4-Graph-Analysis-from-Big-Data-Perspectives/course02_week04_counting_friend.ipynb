{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting number of the mutual friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each user having ID in the column userId count the amount of his / her common friends with each other user having ID in the column userId.\n",
    "\n",
    "Print 49 pairs of the users having the largest amount of common friends, ordered in descending order first by the common friends count , then by id of user1 and finally by id of user 2. The format is following: \"count user1 user2\"7\n",
    "\n",
    "Example:\n",
    "\n",
    "234\t54719\t767867<br>\n",
    "120\t54719 767866<br>\n",
    "97 50787 327676<br>\n",
    "\n",
    "To solve this task use the algorithm described in the last video of lesson 1. The overall plan could look like this:\n",
    "\n",
    "- Create a new column “friend” by exploding of column “friends” (like in the demo iPython notebook)<br>\n",
    "- group the resulting dataframe by the column “friend” (like in the demo iPython notebook)<br>\n",
    "- create a column “users” by collecting all users with the same id in the column “friend” together (like in the demo iPython notebook)<br>\n",
    "- sort the elements in the column “users” by the function sort_array<br>\n",
    "- filter only the rows which have more than 1 element in the column “users”<br>\n",
    "- for each row emit all possible ordered pairs of users from the column “users” (tip: write a user defined function for this)<br>\n",
    "- count the number of times each pair has appeared<br>\n",
    "- with the help of the window function (like in the demo python notebook) select 49 pairs of users who have the biggest amount of common friends<br>\n",
    "The sample dataset is located at /data/graphDFSample.\n",
    "\n",
    "The part of the result on the sample dataset:\n",
    "\n",
    "\n",
    "3044 21864412 51640390<br>\n",
    "3021 17139850 51640390<br>\n",
    "3010 14985079 51640390<br>\n",
    "2970 17139850 21864412<br>\n",
    "2913 20158643 27967558<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.1.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.12 (default, Nov 19 2016 06:48:10)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder.enableHiveSupport().master(\"local [2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sample \n",
    "# +--------+--------------------+\n",
    "# |    user|             friends|\n",
    "# +--------+--------------------+\n",
    "# |22991438|[20699, 175973, 5...|\n",
    "# +--------+--------------------+\n",
    "# assume that user 22991438 follows users 20699, 175973, 5...\n",
    "# for each pair of user (A, B), count the number of users that both of them follow?\n",
    "# without combine to columns\n",
    "# in this case direction is important\n",
    "# algorithm:\n",
    "# explode friends colum to new column named friend\n",
    "# now we have \"user\" follows \"friend\" in each row\n",
    "# group by \"friend\" then collect all \"user\" into a list of \"users\"  \n",
    "# now for each \"friend\" we have list her/his followers in column \"users\"\n",
    "# sort user ids in \"users\" lists, and emit this list to all possible pair\n",
    "# i.e. each pair of \"users\" follow \"friend\"\n",
    "# count the number of time each pair occurs\n",
    "# this will be the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphPath = \"/data/graphDFSample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, collect_list, size, col, row_number\n",
    "from pyspark.sql import Window\n",
    "\n",
    "# Create a new column “friend” by exploding of column “friends” (like in the demo iPython notebook)\n",
    "# group the resulting dataframe by the column “friend” (like in the demo iPython notebook)\n",
    "# create a column “users” by collecting all users with the same id in the column “friend” together (like in the demo iPython notebook)\n",
    "# sort the elements in the column “users” by the function sort_array\n",
    "\n",
    "reversedGraph = sparkSession.read.parquet(graphPath) \\\n",
    "    .withColumn(\"friend\", explode('friends')) \\\n",
    "    .groupBy(\"friend\") \\\n",
    "    .agg(collect_list(\"user\").alias(\"users\"))\n",
    "#     .withColumn(\"users_size\", size(\"users\")) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reversedGraph.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the elements in the column “users” by the function sort_array\n",
    "from pyspark.sql.functions import sort_array\n",
    "reversedGraph = reversedGraph.withColumn(\"users\", sort_array(\"users\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only the rows which have more than 1 element in the column “users”\n",
    "reversedGraph = reversedGraph.filter(size('users') > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reversedGraph.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each row emit all possible ordered pairs of users from the column “users” (tip: write a user defined function for this)\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, IntegerType\n",
    "from itertools import combinations\n",
    "# udf_friend_pair = udf(friend_pair, ArrayType)\n",
    "def emit_all_pairs(users):\n",
    "    return list(combinations(users, 2))\n",
    "\n",
    "schema = ArrayType(IntegerType())\n",
    "udf_emit_all_pairs = udf(emit_all_pairs, ArrayType(schema))\n",
    "\n",
    "df = reversedGraph.withColumn(\"pairs\", udf_emit_all_pairs(col(\"users\")))\n",
    "# df.take(2)\n",
    "# [Row(friend=148, users=[3195315, 14631101, 14957568, 65051219], pairs=[[3195315, 14631101], [3195315, 14957568], [3195315, 65051219], [14631101, 14957568], [14631101, 65051219], [14957568, 65051219]])]\n",
    "# emit_all_pairs([2,3,4])\n",
    "# [(2, 3), (2, 4), (3, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of times each pair has appeared\n",
    "from pyspark.sql.functions import count\n",
    "df = df.select(explode(\"pairs\").alias('pair'))\\\n",
    "       .withColumn('a', col(\"pair\").getItem(0))\\\n",
    "       .withColumn('c', col(\"pair\").getItem(1))\\\n",
    "       .groupBy('a', 'c')\\\n",
    "       .agg(count(\"*\").alias(\"number_common_followeds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the help of the window function (like in the demo python notebook) select 49 pairs of users who have the biggest amount of common friends\n",
    "# The sample dataset is located at /data/graphDFSample.\n",
    "window = Window.orderBy(col(\"number_common_followeds\").desc())\n",
    "top50 = df.withColumn(\"row_number\", row_number().over(window))\\\n",
    "          .filter(col(\"row_number\") < 50) \\\n",
    "          .select(col('a'), col('c'), col('number_common_followeds'))\\\n",
    "          .orderBy(col('number_common_followeds').desc(), col('a').desc(), col('c').desc())\\\n",
    "          .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# window = Window.orderBy(col(\"users_size\").desc())\n",
    "    \n",
    "# top50 = reversedGraph.withColumn(\"row_number\", row_number().over(window)) \\\n",
    "#             .filter(col(\"row_number\") < 50) \\\n",
    "#             .select(col(\"friend\"), col(\"users_size\")) \\\n",
    "#             .orderBy(col(\"users_size\").desc()) \\\n",
    "#             .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3206 27967558 42973992\n",
      "3130 20158643 42973992\n",
      "3066 22582764 42973992\n",
      "3044 21864412 51640390\n",
      "3021 17139850 51640390\n",
      "3010 14985079 51640390\n",
      "2970 17139850 21864412\n",
      "2913 20158643 27967558\n",
      "2903 22280814 51151280\n",
      "2870 23848749 51640390\n",
      "2855 20158643 22582764\n",
      "2849 20158643 44996025\n",
      "2846 22280814 42973992\n",
      "2784 21864412 23848749\n",
      "2779 31964081 51640390\n",
      "2776 39205988 51640390\n",
      "2754 17139850 23848749\n",
      "2749 22582764 27967558\n",
      "2728 50561859 51640390\n",
      "2724 15485897 51640390\n",
      "2700 28135661 42973992\n",
      "2655 22280814 27967558\n",
      "2653 42973992 43548989\n",
      "2639 26755857 51640390\n",
      "2621 14635589 51640390\n",
      "2608 15485897 17139850\n",
      "2606 17139850 26755857\n",
      "2601 21864412 39205988\n",
      "2600 8406745 51640390\n",
      "2599 37735419 51640390\n",
      "2597 20158643 28135661\n",
      "2585 40003405 42973992\n",
      "2585 21864412 31964081\n",
      "2581 27967558 43548989\n",
      "2579 23848749 31964081\n",
      "2578 27967558 28135661\n",
      "2578 15485897 21864412\n",
      "2577 42973992 64755069\n",
      "2574 51151280 57077210\n",
      "2573 20158643 43548989\n",
      "2566 21864412 26755857\n",
      "2564 22280814 64755069\n",
      "2561 42973992 44996025\n",
      "2556 17139850 39205988\n",
      "2543 23848749 39205988\n",
      "2521 17139850 31964081\n",
      "2515 27967558 44996025\n",
      "2506 41629539 51640390\n",
      "2505 51151280 64755069\n"
     ]
    }
   ],
   "source": [
    "for val in top50:\n",
    "    print '%s %s %s' % (val[2], val[0], val[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
